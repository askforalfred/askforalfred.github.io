<!doctype html>
<html lang="en">
  <head>

    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-8024377-10', 'auto');
      ga('create', 'UA-25750945-3', 'auto', 'jesseTracker');
      ga('send', 'pageview');
      ga('jesseTracker.send', 'pageview');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="Mark Otto, Jacob Thornton, and Bootstrap contributors">
    <meta name="generator" content="Jekyll v3.8.5">
    <title>ALFRED+TEACh @ CVPR 2023 </title>

    <link rel="canonical" href="http://askforalfred.com/EAI">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css" integrity="sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS" crossorigin="anonymous">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0">
    <meta name="twitter:title" content="ALFRED">
    <meta name="og:title" content="ALFRED">
    
    <meta name="description" content="A Benchmark for Interpreting Grounded Instructions for Everyday Tasks">
    <meta name="twitter:description" content="A Benchmark for Interpreting Grounded Instructions for Everyday Tasks">
    <meta property="og:description" content="A Benchmark for Interpreting Grounded Instructions for Everyday Tasks">

    <meta property="og:image" content="https://askforalfred.com/images/alfred_bg.jpg">
    <meta name="twitter:image" content="https://askforalfred.com/images/alfred_bg.jpg">
    <meta name="twitter:card" content="summary_large_image">
    
    <meta property="twitter:image:width" content="1200">
    <meta property="twitter:image:height" content="630">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <script>
      /**
      * Function that captures a click on an outbound link in Analytics.
      * This function takes a valid URL string as an argument, and uses that URL string
      * as the event label. Setting the transport method to 'beacon' lets the hit be sent
      * using 'navigator.sendBeacon' in browser that support it.
       */
        var captureOutboundLink = function(url) {
          ga('send', 'event', 'outbound', 'click', url, {
            'transport': 'beacon'
          });
          ga('jesseTracker.send', 'event', 'outbound', 'click', url, {
            'transport': 'beacon'
          });
          // 'hitCallback': function(){document.location = url;}
          //});
          return false;
        }
    </script>

    <!--
    <script>
    // Set the date we're counting down to
    var countDownDate = new Date("Aug 5, 2021 0:0:0").getTime();
    
    // Update the count down every 1 second
    var x = setInterval(function() {
    
      // Get today's date and time
      var now = new Date().getTime();
    
      // Find the distance between now and the count down date
      var distance = countDownDate - now;
    
      // Time calculations for days, hours, minutes and seconds
      var days = Math.floor(distance / (1000 * 60 * 60 * 24));
      var hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
      var minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60));
      var seconds = Math.floor((distance % (1000 * 60)) / 1000);
    
      // Display the result in the element with id="demo"
      document.getElementById("date").innerHTML = days + " days " + hours + ":"
      + minutes + ":" + seconds;
    
      // If the count down is finished, write some text
      if (distance < 0) {
        clearInterval(x);
        document.getElementById("date").innerHTML = "Aug 5, 2021";
      }
    }, 1000);
    </script>
    -->

    <style>
.bd-placeholder-img {
  font-size: 1.125rem;
  text-anchor: middle;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

    @media (min-width: 768px) {
      .bd-placeholder-img-lg {
        font-size: 3.5rem;
      }
    }

    #leaderboard 
    {
      width:500;
      height:400;
      position:absolute;
      overflow:hidden;
    }


    #innerIframe
    {
      position:relative;
      top:-550px;
      left:0px;
      width:500px;
      height:900px;
    }

    .performanceTable tr.human-row {
        background: #f5f5f5;
    }

    .performanceTable tr.random-row {
        background: #fafafa;
    }

    .performanceTable {
        margin-left: auto;
        margin-right: auto;
        max-width: 90%;
        border: 1px solid #ccc;
        background-color: #9da3bf14;
        border-radius: 4px;
    }

    .performanceTable .institution {
        font-style: italic;
        font-weight: 300;
    }

    .performanceTable .date {
        font-weight: normal;
        background-color: #777;
        display: inline;
        padding: .2em .6em .3em;
        font-size: 75%;
        line-height: 1;
        color: #fff;
        text-align: center;
        white-space: nowrap;
        vertical-align: baseline;
        border-radius: .25em;
    }

    .performanceTable td,
    .performanceTable th {
        text-align: center;
        max-width: 250px;
    }



    table tr *:nth-child(3) {
      border-right: 1px dashed #bfbfbf;
      border-left: 1px dashed #bfbfbf;
    }

    table tr *:nth-child(4) {
      border-right: 1px dashed #bfbfbf;
      border-left: 1px dashed #bfbfbf;
    }

    table tr *:nth-child(5) {
      border-right: 1px dashed #bfbfbf;
      border-left: 1px dashed #bfbfbf;
    }

    table tr *:nth-child(6) {
      border-right: 1px dashed #bfbfbf;
      border-left: 1px dashed #bfbfbf;
    }


/*    table tr *:nth-child(5) {
      border-right: 1px dashed #bfbfbf;
    }*/
    /*table tr td:nth-child(5) {*/
      /*border-right: 1px dashed #bfbfbf;*/
    /*}*/


    </style>

    <!-- Custom styles for this template -->
    <link href="https://getbootstrap.com/docs/4.3/examples/jumbotron/jumbotron.css" rel="stylesheet">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="../index.css">


  </head>


  <body style="padding-top: 0px;">
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
      <a class="navbar-brand" href="#">ALFRED+TEACh @ CVPR 2023</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" 
                                                   data-target="#navbars" aria-controls="navbars" 
                                                                          aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbars">
        <div class="navbar-nav">
          <a class="nav-item nav-link active" href="#">Home <span class="sr-only">(current)</span></a>
          <a class="nav-item nav-link" href="https://askforalfred.com" 
              onclick="captureOutboundLink('https://askforalfred.com');">ALFRED</a>
          <a class="nav-item nav-link" href="https://teachingalfred.github.io/" 
              onclick="captureOutboundLink('https://teachingalfred.github.io/');">TEACh</a>
        </div>
      </div>
    </nav>

    <main role="main">

    <!-- Main jumbotron -->

    <div class="jumbotron">
      <div class="row">
        <div class="col-md-12" align="left">
        <p>
          <h1>Generalist Language Grounding Agents Challenge</h1>
          </p>
          <h3>Embodied AI Workshop @ CVPR 2023</h3>
          <br/>
        <p>
        Recent embodied agents have been successful in learning navigation and interaction skills from large-scale datasets, but progress has been limited to single-setting domains like either instruction-following or dialogue-driven tasks. To avoid over-specialization of models to specific datasets and tasks, this challenge encourages the development of <b>generalist language grounding agents</b> whose architectures transfer language-understanding and decision-making capabilities across tasks. For this first iteration, we unify aspects of the ALFRED and TEACh datasets. While both datasets are set in the Ai2THOR simulator, they differ along several axes:
        </p>
        <ul>
          <li>Declarative (ALFRED) vs Dialogue (TEACh) language introduces grounding and alignment challenges</li>
          <li>Agent heights change depth estimation and segmentation pipelines</li>
          <li>Changes to the action spaces and room layout require world model generalization</li>
        </ul>
        Participants will submit independently to each leaderboard, and submissions will be ranked by a combined unseen success metric. 
        <br/>
        <br/>
        </div>

        <div class="col-md-1"></div>
        <div class="col-md-5">
            <div class="row">
            <div class="col-md-12" align="center">
              <img width=100 src="photos/ALFRED.png">
            </div> <!-- col 7-->

          </div> <!-- row -->
          <br><br>

          <a href="https://leaderboard.allenai.org/alfred/submissions/public">The ALFRED Leaderboard</a> is accepting submissions to the <a href="https://embodied-ai.org/" target="_blank" onclick="captureOutboundLink('https://embodied-ai.org/');">Embodied AI Challenge</a> with <code>[EAI23]</code> tags!  Humans have a success rate of 91% on unseen environments, but the best models are still far behind üò¢<br/>
          <br/>
          Can you do even better? <a href="https://github.com/askforalfred/alfred">Code, precomputed features, and AI2Thor simulator</a> are all available on Github. For a quick start, checkout <a href="https://github.com/soyeonm/FILM" target="_blank">FILM ‚Äì a SoTA agent</a>. 
          <br/>
          <br/>
        </div> <!--col-->

        <div class="col-md-5">
            <div class="row">
            <div class="col-md-12" align="center">
              <img width=107 src="photos/teach_emoji.png">
            </div> <!-- col 7-->

          </div> <!-- row -->
          <br><br>

          <a href="https://github.com/GLAMOR-USC/teach_tatc">The TEACh Leaderboard</a> is coming soon! Submit your agent with the <code>[EAI23]</code> tags. The best performing agents have a unseen success rate of <1% üòñ<br/>
          <br/>
          <br/>
          Can you do even better? <a href="https://github.com/GLAMOR-USC/teach_tatc">Code and baselines</a> are all available on Github.</a>
          <br/>
          <br/>
        </div> <!--col-->
    </div>
    </main>
      <br>

<div class="container">
      <h2><a href="https://askforalfred.com" target="_blank" onclick="captureOutboundLink('https://askforalfred.com');">Challenge Environment</a></h2>
      <br>
      <div class="row">
            <iframe width="100%" height="600" id="ytVid" src="https://www.youtube.com/embed/1XoRLNmXffo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div> <!-- /container -->
            
    <hr>

    <div class="container">
      <br>
        <br>
        <div class="container">
          <h3><b>Overview</b></h3>
          <div class="row">
            <div class="col-md-6">
              <br>
              <p> 
              The focus of this challenge is to build generalist embodied agents that map language to actions in embodied settings. Specifically, we want agents to be capable of solving instruction-following and dialogue-driven grounding tasks. These tasks involve challenges like partial observability, continuous state spaces, and irrevocable actions in rich visual environments.
              Such challenges are not captured by prior datasets for embodiment [<a href="https://bringmeaspoon.org/">1</a>, <a href="https://homes.cs.washington.edu/~xkcd/papers/iqa.html">2</a>, <a href="https://embodiedqa.org/">3</a>].
              </p>
            </div> <!-- col 7-->
            <div class="col-md-6">
              <ul><b>Key Topics</b>
                <li>Egocentric and Robotic vision</li>
                <li>Language Grounding</li>
                <li>Dialogue-Driven Grounding</li>
                <li>Navigation and Path Planning</li>
                <li>Interactive/Causal Reasoning</li>
                <li>Learning from Demonstration</li>
                <li>Task and Symbolic Planning</li>
                <li>Deep Reinforcement Learning</li>
                <li>Commonsense Reasoning</li>
              </ul>
            </div> <!-- col 5-->
          </div> <!-- row -->
          <div class="row">
            <div class="col-md-10">
              The challenge is based on two benchmarks: <a href="http://askforalfred.com">ALFRED</a> and <a href="https://teachingalfred.github.io/">TEACh</a>. 
              This workshop exists to bring together Vision, Robotics, and NLP researchers to tackle the unique challenges of this three-field intersection that are often avoided when focusing only on vision-and-language or vision-and-robotics (i.e., 'embodied AI').
            </div> <!-- /col -->
              <div class="col-md-10">
              <br>
              Previous versions of this challenge were held at <a href="https://askforalfred.com/EAI22/">CVPR 2022</a>, <a href="https://askforalfred.com/EAI21/">CVPR 2021</a> and <a href="https://askforalfred.com/EVAL/">ECCV 2020</a>. 
            </div> <!-- /col -->
          </div> <!-- /row -->
        </div> <!-- container -->
      <br>
      <div class="container">
          <div class="row">
            <div class="col">
                <table style="display: inline-block;"><tr><td>
                <a href="https://mohitshridhar.com/" target="_blank" 
                   onclick="captureOutboundLink('https://mohitshridhar.com/');">
                   <center><img src="photos/mohitshridhar.png" height=100><br>Mohit Shridhar</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://ishikasingh.github.io/" target="_blank" 
                   onclick="captureOutboundLink('https://ishikasingh.github.io/');">
                   <center><img src="photos/ishika.jpeg" height=100><br>Ishika Singh</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://aliang8.github.io/" target="_blank" 
                   onclick="captureOutboundLink('https://aliang8.github.io/');">
                   <center><img src="photos/anthony.jpeg" height=100><br>Anthony Liang</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="http://soyeonm.github.io/" target="_blank" 
                   onclick="captureOutboundLink('http://soyeonm.github.io/');">
                   <center><img src="photos/tiffanymin.jpg" height=100><br>Tiffany Min</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://www.zhuhao.me/" target="_blank" 
                   onclick="captureOutboundLink('https://www.zhuhao.me/');">
                   <center><img src="photos/hao_zhu.jpeg" height=100><br>Hao Zhu</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://jiminsun.github.io/" target="_blank" 
                   onclick="captureOutboundLink('https://jiminsun.github.io/');">
                   <center><img src="photos/jimin.jpeg" height=100><br>Jimin Sun</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://yonatanbisk.com/" target="_blank" 
                   onclick="captureOutboundLink('https://yonatanbisk.com/');">
                   <center><img src="photos/YonatanBisk.jpg" height=100><br>Yonatan Bisk</a></center>
                </td></tr></table>
                <table style="display: inline-block;"><tr><td>
                <a href="https://jessethomason.com/" target="_blank" 
                   onclick="captureOutboundLink('https://jessethomason.com/');">
                   <center><img src="photos/jessethomason.jpg" height=100><br>Jesse Thomason</a></center>
                </td></tr></table>
              </div>
            </div>
        </div> <!-- container -->

      <hr>

    <div class="container">
      <div class="row">
        
      </div> <!-- row -->
    </div> <!-- container -->
    <div class="container">
      <div class="row">
        <div class="col-md-11">
          </br>
          <h4>Important Dates</h4>
          <table>
            <tr><td colspan=2><hr align=left width=250><b>Timeline</b></td></tr>
            <tr><td>Challenge Opens</td><td> Mar 12</td></tr>
            <tr><td>Leaderboard closes</td><td> Jun 12 </td></tr>
            <tr><td>Winner announcement </td><td>Jun 17</td></tr>
          </table>
          </br>
          </br>
        </div> <!-- col 5 --> 

        <div class="col-md-11">
          <h4>Challenge Details</h4>
          <p>
          Participants will submit their best agents to both leaderboards independently. Submissions <b>must be from a single agent</b> that is evaluated on both ALFRED and TEACh. The top two submissions will have the opportunity to present their methods at the Embodied AI workshop.
          </br>
          </br>
          </p>
          <h5>1Ô∏è‚É£ ALFRED Challenge</h5>
          <p><b>Guidelines</b> <br>Participants are required to upload their model to  our  <a href="https://leaderboard.allenai.org/alfred/submissions/public" target="_blank" onclick="captureOutboundLink('https://leaderboard.allenai.org/alfred/submissions/public');">evaluation  server</a>  with <code>[EAI23]</code> in the submission title, e.g. <i>[EAI23] Seq2seq Model</i>.   The  evaluation  server  automatically  evaluates  the models on an unseen test set.  Final numbers for the prize challenge will be frozen on <b>Jun 12</b>. Winning submissions will be required to submit a <b>brief (private) report of technical details</b> for validity checking. We will also <b>conduct a quick code inspection</b> to ensure that the challenge rules weren't violated (e.g. using additional info from test scenes).</p>
          <p><b>Dataset</b><br> The challenge is based on the <a href="https://github.com/askforalfred/alfred" target="_blank">ALFRED Dataset</a>, which contains 25K language annotations of both high-level goals and low-level step-by-step instructions for various tasks set in the <a href="https://ai2thor.allenai.org/" target="_blank">AI2THOR</a> simulator. Agents interact with environments through discrete actions and pixelwise masks. </p>
        </div> <!-- col 5 -->

        <div class="col-md-11">
          <p><b>Starter Code</b><br>
          Checkout the <a href="https://github.com/soyeonm/FILM" target="_blank">FILM repository</a> by So Yeon Min et al.</p>
          <p><b>Evaluation</b><br> The leaderboard script records actions taken by a pre-trained agent and dumps them to a JSON file. These deterministic actions in the JSON will be replayed on the leaderboard server for evaluation. This process is model-agnostic, allowing you to use your local resources for test-time inference. </p>
          <p><b>Metric</b><br> The submissions will be ranked by Unseen Success Rate. </p>
          <p><b>Rules</b><br> 
          <ol>
            <li>Include <code>[EAI23]</code> in the submission title e.g. <i>[EAI23] Seq2seq Model</i>.</li>
            <li>Do not exploit the metadata in test-scenes: you should solve the vision-language grounding problem without misusing the metadata from THOR. For leaderboard evaluations, agents should just use <b>RGB input</b> and <b>language instructions (goal & step-by-step)</b>. You <b>cannot use additional depth, mask, metadata info etc. from the simulator on Test Seen and Test Unseen scenes.</b> Submissions that use additional info on test scenes will be disqualified. 
            However, during training you are allowed to use additional info for auxiliary losses etc.</li>
            <li>During evaluation, agents are restricted to <code>max_steps=1000</code> and <code>max_fails=10</code>. Do not change these settings in the <a href="https://github.com/askforalfred/alfred/blob/master/models/eval/leaderboard.py#L220" target="_blank">leaderboard script</a>; these modifications will not be reflected in the evaluation server.</li>
            <li>You can publish your results on the leaderboard only once every 7 days.</li>
            <li>Do not spam the leaderboard with repeated submissions (under different email accounts) in order to optimize on the test set. Fine-tuning should be done only on the validation set. Violators will be disqualified from the challenge.</li>
            <li>Try to solve the ALFRED dataset: all submissions must be attempts to solve the ALFRED dataset.</li>
            <li>Answer the following questions: a. Did you use additional sensory information from THOR as input, eg: depth, segmentation masks, class masks, panoramic images etc. during test-time? If so, please report them. b. Did you use the alignments between step-by-step instructions and expert action-sequences for training or testing? (no by default; the instructions are serialized into a single sentence)</li>
            <li>Share who you are: you must provide a team name and affiliation.</li>
            <li>(Optional) Share how you solved it: if possible, share information about how the task was solved. Link an academic paper or code repository if public.</li>
            <li>Only submit your own work: you may evaluate any model on the validation set, but must only submit your own work for evaluation against the test set.</li>
          </ol>

          </br>
          <h5>2Ô∏è‚É£ TEACh Challenge</h5>
          Details coming soon ...

          </br>
          </br>
          <h5>üìà Evaluation Metric </h5>
          Submissions will be ranked by a combined score that equally weighs Unseen Success Rates from both ALFRED and TEACh:
          </br>
          <div style="text-align:center">
            <div id="equation">
              $$\textrm{Combined}_{\textrm{Unseen Success}}\ =\ \frac{1}{2} (\textrm{ALFRED}_{\textrm{Unseen Success}} +\ \textrm{TEACh}_{\textrm{Unseen Success}})$$
            </div>
          </div>  

          </p>
        </div>
      </div>
    </div>


    <hr>

    <div class="container">
        <div class="container">
          <h3><b>Submissions</b></h3>
          <br>
          <div class="col-md-13">
               <table class="table performanceTable box-shadow">
                    <tbody>
                    <tr>
                        <th>Rank</th>
                        <th style="min-width: 25%;">Model</th>
                        <th style="max-width: 10%;">ALFRED<br>Unseen Success</th>
                        <th style="max-width: 10%;">ALFRED<br>Unseen PLW</th>
                        <th style="max-width: 10%;">TEACh<br>Unseen Success</th>
                        <th style="max-width: 10%;">TEACh<br>Unseen PLW</th>
                        <th style="max-width: 10%;"><br>Combined</th>
                    </tr>
                    <tr class="human-row">
                        <td></td>
                        <td>Human Performance<p class="institution">University of Washington</p><a
                                href="https://arxiv.org/abs/1912.01734" target="_blank" >(Shridhar et al. '20)</a></td>
                        <td>91.0</td>
                        <td>87.6</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
<tr><td><p>-</p></td><td>Seq2seq Baseline<p class="institution">University of Washington, Amazon, USC Viterbi</p> </td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr>
                    </tbody>
                </table>
          </div> <!-- col 7-->
        </div>
        <br>
    </div>
    <hr>

    <div class="container">
      <div class="row">
        <div class="col-md-11">
          <h4>FAQ</h4>
            <ul>
              <li><b>Do we need to submit a report?</b> <br>Winning submissions will be required to submit a brief (private) report of technical details for validity checking. Also consider submitting a workshop paper to EAI. See <a href="https://embodied-ai.org/" target="_blank">submission guidelines for EAI</a>.</li><br>
              <li><b>Do we need to submit a video?</b><br>
              The top two winning submission will need to submit a brief video explaining their methods and results. These videos will be featured on this website and during the EAI workshop.  
              </li>
              <br>
              <li><b>Is there a prize for the winner?</b><br>TBA</li><br>
            </ul>
          </h4>
        </div>
      </div>
    </div>
    <hr>

    <footer class="container">
      <p>Questions or issues?  Contact <a href="mailto:askforalfred@googlegroups.com">askforalfred@googlegroups.com</a></p>
    </footer>
  </body>
</html>

